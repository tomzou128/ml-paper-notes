## VITS

Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech



### 引言

传统方法使用二阶段的方法，首先从文本到频谱，然后从频谱到波形。目前提出了端到端的方法，直接从文本到波形。提出了一种并行的端到端 TTS 方法，该方法比当前的两阶段模型产生更自然的声音。该方法采用了基于 cVAE + Flow + GAN 提高了生成建模的表达能力。我们还提出了一个随机时长预测器，对同样的文本合成具有不同音调和节奏的语音。通过预测一个分布而不是期望值，然后在当中进行随机采样。该方法表达了自然的一对多关系。



vits 依赖于韵律标注，



### 方法



## 代码实现